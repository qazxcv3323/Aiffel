{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vietnamese-favorite",
   "metadata": {},
   "source": [
    "# Exploration_10_텍스트요약\n",
    "## 순서\n",
    "\n",
    "### Step 1. 데이터 수집 \n",
    "### Step 2. 전처리 \n",
    "### Step 3. Attention 메커니즘 사용 (abstractive) \n",
    "### Step 4. 실제결과와 요약문 비교 \n",
    "### Step 5. Summa 사용 (extractive) \n",
    "\n",
    "우수노드 장재성님 코드 참고\n",
    "https://github.com/jangjs1103/laboratory/blob/main/AIFFEL/LMS/Exploration_10/Exploration_10_요약문.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-paint",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hidden-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85902</th>\n",
       "      <td>May break Islamist militants' city siege soon:...</td>\n",
       "      <td>Philippine Army has said that it is close to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84121</th>\n",
       "      <td>Daddy isn't a propaganda film: Rampal on Arun ...</td>\n",
       "      <td>Arjun Rampal, talking about his upcoming biopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75256</th>\n",
       "      <td>Preity Zinta shares throwback picture with Ais...</td>\n",
       "      <td>Actress Preity Zinta took to Instagram to shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>Madhuri not contesting Lok Sabha elections: Sp...</td>\n",
       "      <td>Madhuri Dixit's spokesperson has denied report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>Amazon rainforest deforestation hits highest l...</td>\n",
       "      <td>Deforestation of the Amazon rainforest has rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75115</th>\n",
       "      <td>Sharapova to make first Grand Slam appearance ...</td>\n",
       "      <td>Five-time Grand Slam winner Russian tennis pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34232</th>\n",
       "      <td>Google CEO Sundar Pichai to receive $380 mn pa...</td>\n",
       "      <td>Google CEO Sundar Pichai will receive a payout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>'Namaste England' changes poster over wrong In...</td>\n",
       "      <td>Arjun Kapoor and Parineeti Chopra's upcoming f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66019</th>\n",
       "      <td>Delhi's first ''pink toilet'' for women launched</td>\n",
       "      <td>The South Delhi Municipal Corporation inaugura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58847</th>\n",
       "      <td>Honeypreet, 11 more charged with sedition for ...</td>\n",
       "      <td>Gurmeet Ram Rahim's adopted daughter Honeypree...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "85902  May break Islamist militants' city siege soon:...   \n",
       "84121  Daddy isn't a propaganda film: Rampal on Arun ...   \n",
       "75256  Preity Zinta shares throwback picture with Ais...   \n",
       "7144   Madhuri not contesting Lok Sabha elections: Sp...   \n",
       "8805   Amazon rainforest deforestation hits highest l...   \n",
       "75115  Sharapova to make first Grand Slam appearance ...   \n",
       "34232  Google CEO Sundar Pichai to receive $380 mn pa...   \n",
       "21442  'Namaste England' changes poster over wrong In...   \n",
       "66019   Delhi's first ''pink toilet'' for women launched   \n",
       "58847  Honeypreet, 11 more charged with sedition for ...   \n",
       "\n",
       "                                                    text  \n",
       "85902  Philippine Army has said that it is close to e...  \n",
       "84121  Arjun Rampal, talking about his upcoming biopi...  \n",
       "75256  Actress Preity Zinta took to Instagram to shar...  \n",
       "7144   Madhuri Dixit's spokesperson has denied report...  \n",
       "8805   Deforestation of the Amazon rainforest has rea...  \n",
       "75115  Five-time Grand Slam winner Russian tennis pla...  \n",
       "34232  Google CEO Sundar Pichai will receive a payout...  \n",
       "21442  Arjun Kapoor and Parineeti Chopra's upcoming f...  \n",
       "66019  The South Delhi Municipal Corporation inaugura...  \n",
       "58847  Gurmeet Ram Rahim's adopted daughter Honeypree...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genuine-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98401"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터 수\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-planner",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessory-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "# 중복 제외 데이터 수\n",
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "happy-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# text column 중복 제거\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interested-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-program",
   "metadata": {},
   "source": [
    "#### 정규화 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화를 위한 정규화 사전 구성\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-hierarchy",
   "metadata": {},
   "source": [
    "#### 불용어 확인, 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "warming-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 (stopwords) 확인\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floating-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수 작동 확인\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accurate-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426.8617663383484  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament despite withdrawal support immediate threat government']\n",
      "12.983286380767822  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "# text 전처리\n",
    "clean_text = preprocess_data(data['text'])\n",
    "print(clean_text)\n",
    "\n",
    "# headlines 전처리\n",
    "clean_summary = preprocess_data(data['headlines'], remove_stopwords=False)\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "golden-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존의 data를 전처리 된 data로 치환\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 값 재 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civic-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "shared-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 16\n",
      "헤드라인의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gentle-aside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "similar-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 형태로 변경\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "centered-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98360,)\n",
      "(98360,)\n",
      "(98360,)\n"
     ]
    }
   ],
   "source": [
    "# shape 확인\n",
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "institutional-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2528  9843 95923 ... 77092 15505 87244]\n",
      "98360\n"
     ]
    }
   ],
   "source": [
    "# 랜덤으로 값을 배분하기 위한 shuffle 진행\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seventh-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle 된 값으로 치환\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "illegal-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19672\n",
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "# 'train : test = 8 : 2' 비율로  set 구성\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)\n",
    "\n",
    "# train set\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "# test set\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-celebrity",
   "metadata": {},
   "source": [
    "#### 단어집합 (vocabulary) 만들기 : Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "horizontal-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Text' 에 대한 처리 시작\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "failing-mercury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 1),\n",
       " ('india', 2),\n",
       " ('year', 3),\n",
       " ('added', 4),\n",
       " ('us', 5),\n",
       " ('also', 6),\n",
       " ('first', 7),\n",
       " ('government', 8),\n",
       " ('police', 9),\n",
       " ('people', 10)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화가 잘 되었는지 확인\n",
    "list(src_tokenizer.word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "working-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69534\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47395\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22139\n",
      "단어 집합에서 희귀 단어의 비율: 68.16089970374205\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.486458182881771\n"
     ]
    }
   ],
   "source": [
    "# 빈도수에 따른 단어의 중요도 확인\n",
    "\n",
    "threshold = 7 # 빈도수 제한 : 7 미만\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "provincial-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 22000 # 단어 집합크기 제한\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 22,000로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "divided-election",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 696, 1476, 535, 4207, 406, 621, 5443, 1273, 852, 768, 696, 1799, 1687, 1363, 1476, 533, 34, 1, 10275, 2402, 5714, 186, 226, 1012, 3746, 1476, 533, 1687, 15382, 621, 320], [66, 28, 450, 114, 40, 99, 1328, 3063, 148, 46, 413, 292, 294, 797, 28, 298, 1, 1344, 12, 109, 3951, 9643, 6784, 1, 685, 292, 1677, 9292, 12, 8680, 4], [1144, 32, 520, 626, 7, 3485, 5260, 218, 10037, 741, 346, 10276, 69, 1768, 2459, 3026, 788, 1739, 3485, 829, 1087, 3952, 2616, 51, 23, 105, 3027, 10776, 1284, 246, 346, 1768, 7460]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "missing-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Headlines' 에 대해 동일하게 처리\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "federal-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30064\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20548\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9516\n",
      "단어 집합에서 희귀 단어의 비율: 68.34752527940394\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.2903974184153855\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "floating-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 9500 # 위의 결과에 따라 설정\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "musical-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 288, 6, 390, 1316, 2847, 213, 3782], [1, 50, 2243, 76, 109, 17, 28, 283, 812, 1899], [1, 1974, 9, 4139, 4837, 16, 3392, 1838], [1, 8, 6463, 594, 2642, 1531, 4, 18, 4019], [1, 81, 5877, 167, 58, 10, 384, 355, 959, 285]]\n",
      "target\n",
      "decoder  [[288, 6, 390, 1316, 2847, 213, 3782, 2], [50, 2243, 76, 109, 17, 28, 283, 812, 1899, 2], [1974, 9, 4139, 4837, 16, 3392, 1838, 2], [8, 6463, 594, 2642, 1531, 4, 18, 4019, 2], [81, 5877, 167, 58, 10, 384, 355, 959, 285, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "breeding-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 1\n"
     ]
    }
   ],
   "source": [
    "# 문장의 길이가 1 인 것들은 'sostoken' or 'eostoken' 만 남은 것이므로 제거\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "atomic-ambassador",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19671\n",
      "테스트 레이블의 개수 : 19671\n"
     ]
    }
   ],
   "source": [
    "# drop_train, drop_test 에 대한 값을 제거\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-gross",
   "metadata": {},
   "source": [
    "#### 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "internal-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 60\n",
    "headlines_max_len = 16\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "frozen-brisbane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16,  696, 1476, ...,    0,    0,    0],\n",
       "       [  66,   28,  450, ...,    0,    0,    0],\n",
       "       [1144,   32,  520, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 850,   50, 8134, ...,    0,    0,    0],\n",
       "       [ 411, 1426, 1637, ...,    0,    0,    0],\n",
       "       [   2,  413,   17, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_train # 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-hamburg",
   "metadata": {},
   "source": [
    "#### Model 설계 (Encoder, decoder 설계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "extreme-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256 # LSTM 의 capacity에 해당(뉴런의 갯수) but 크다고 항상 좋지않다.\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "continent-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "clear-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      2816000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9500)   2441500     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,312,604\n",
      "Trainable params: 8,312,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-ontario",
   "metadata": {},
   "source": [
    "### Step 3. Attention 함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "certain-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 함수 참조\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "after-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      2816000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9500)   4873500     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,875,932\n",
      "Trainable params: 10,875,932\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-bahrain",
   "metadata": {},
   "source": [
    "#### Model 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "polyphonic-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 328s 1s/step - loss: 4.6581 - val_loss: 3.8771\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 3.8256 - val_loss: 3.5953\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 3.5484 - val_loss: 3.4017\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 318s 1s/step - loss: 3.3346 - val_loss: 3.2750\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 3.1815 - val_loss: 3.1661\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 3.0445 - val_loss: 3.0748\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 313s 1s/step - loss: 2.9319 - val_loss: 3.0034\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 2.8368 - val_loss: 2.9535\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 318s 1s/step - loss: 2.7470 - val_loss: 2.9005\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 2.6753 - val_loss: 2.8656\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.6065 - val_loss: 2.8332\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.5448 - val_loss: 2.8014\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.4880 - val_loss: 2.7808\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.4380 - val_loss: 2.7617\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 313s 1s/step - loss: 2.3896 - val_loss: 2.7451\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.3485 - val_loss: 2.7322\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.3067 - val_loss: 2.7120\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 2.2721 - val_loss: 2.7033\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 319s 1s/step - loss: 2.2323 - val_loss: 2.6935\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.2067 - val_loss: 2.6875\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 315s 1s/step - loss: 2.1822 - val_loss: 2.6759\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 317s 1s/step - loss: 2.1490 - val_loss: 2.6691\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 317s 1s/step - loss: 2.1271 - val_loss: 2.6637\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.0950 - val_loss: 2.6607\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 313s 1s/step - loss: 2.0690 - val_loss: 2.6548\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 314s 1s/step - loss: 2.0506 - val_loss: 2.6462\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 317s 1s/step - loss: 2.0242 - val_loss: 2.6509\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 329s 1s/step - loss: 2.0048 - val_loss: 2.6491\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) # 조기 종료 조건 설정\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "greek-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAroklEQVR4nO3deXxU9b3/8dc3+74vQBYCYZF9C8iiFBEVNxStqK231bbSxVp7763W9lZ79Xdvq7a1antdcKu2V2tFb4vWKlhFFlEM+07CnoSEJGQle+b7++MMIYEAISSZzOT9fDzmMTPnnJn5HObBO9/5nu85X2OtRUREvJ+fpwsQEZGuoUAXEfERCnQRER+hQBcR8REKdBERHxHgqQ9OSEiwGRkZnvp4ERGvtG7duhJrbWJ76zwW6BkZGWRnZ3vq40VEvJIx5sDp1qnLRUTERyjQRUR8hAJdRMRHeKwPXUSkMxobG8nLy6Ours7TpXSrkJAQUlNTCQwM7PBrFOgi4lXy8vKIjIwkIyMDY4yny+kW1lpKS0vJy8tj0KBBHX6dulxExKvU1dURHx/vs2EOYIwhPj7+nH+FKNBFxOv4cpgf15l99LpA311UxX+9u526xmZPlyIi0qt4XaDnldXwwqp9rDtQ5ulSRKQPKi8v5+mnnz7n11111VWUl5d3fUGteF2gT86Iw9/P8OmeEk+XIiJ90OkCvamp6Yyve++994iJiemmqhxeF+iRIYGMS41mdW6pp0sRkT7o/vvvZ8+ePYwfP57Jkydz8cUXM2/ePEaOHAnA9ddfz6RJkxg1ahSLFi1qeV1GRgYlJSXs37+fESNGcOeddzJq1Cguv/xyamtru6Q2rxy2OD0zgaeX51JZ10hUSMfHaIqIb3nonW1sL6js0vccOSCKn1876rTrH3nkEbZu3crGjRtZvnw5V199NVu3bm0ZXvjSSy8RFxdHbW0tkydP5sYbbyQ+Pr7Ne+Tk5PD666/z/PPPs2DBAt566y1uu+22867d61roANOHxOOysHbvUU+XIiJ93JQpU9qMFX/qqacYN24cU6dO5dChQ+Tk5JzymkGDBjF+/HgAJk2axP79+7ukFq9soU9MjyU4wI9P95QyZ2Syp8sREQ85U0u6p4SHh7c8Xr58OR9++CFr1qwhLCyMWbNmtTuWPDg4uOWxv79/l3W5eGULPSTQn6yMWB0YFZEeFxkZSVVVVbvrKioqiI2NJSwsjJ07d/LZZ5/1aG1e2UIHpx/9Vx/soqS6noSI4LO/QESkC8THxzNjxgxGjx5NaGgoycknegnmzp3Ls88+y4gRIxg+fDhTp07t0dq8ONCdgwxr9pRy7bgBHq5GRPqS1157rd3lwcHB/OMf/2h33fF+8oSEBLZu3dqy/Ec/+lGX1eWVXS4AY1KiiQwO4NM9Gr4oIgJeHOgB/n5cODhO/egiIm5eG+jg9KMfKK0hr6zG06WIiHicdwf6EKcfXd0uIiJeHujDkyOJDw9ijQJdRMS7A90Yw7TMeFbnlmCt9XQ5IiIe5dWBDjBjSAJHqurZU3zM06WISB/Q2cvnAjzxxBPU1HTfMT+vD/Tj49E12kVEekJvDnSvPbHouPS4MFJiQvk0t5SvTcvwdDki4uNaXz73sssuIykpib/85S/U19czf/58HnroIY4dO8aCBQvIy8ujubmZBx54gKKiIgoKCrjkkktISEjg448/7vLavD7QjTFMz4xn6fYiml0Wfz/fn2tQRNz+cT8Ubuna9+w3Bq585LSrW18+d+nSpSxevJi1a9dirWXevHmsWLGC4uJiBgwYwN///nfAucZLdHQ0jz/+OB9//DEJCQldW7Nbh7tcjDH+xpgNxph321kXbIx5wxiTa4z53BiT0aVVnsWMIQlU1Day43DXXhdZRORMli5dytKlS5kwYQITJ05k586d5OTkMGbMGJYtW8aPf/xjVq5cSXR0dI/Ucy4t9HuAHUBUO+u+CZRZa4cYY24BHgVu7oL6OmSaux99dW4Jo1N65h9ORHqBM7Ske4K1lp/85Cd8+9vfPmXd+vXree+99/jZz37GpZdeyoMPPtjt9XSohW6MSQWuBl44zSbXAa+4Hy8GLjXG9FjfR3JUCEOSInSCkYh0u9aXz73iiit46aWXqK6uBiA/P58jR45QUFBAWFgYt912G/feey/r168/5bXdoaMt9CeA+4DI06xPAQ4BWGubjDEVQDzQZuiJMWYhsBAgPT29E+We3vTMeN7MzqOhyUVQgNcP3hGRXqr15XOvvPJKvvKVrzBt2jQAIiIi+NOf/kRubi733nsvfn5+BAYG8swzzwCwcOFC5s6dy4ABA7rloKg52wk5xphrgKustd8zxswCfmStveakbbYCc621ee7ne4ALrbWnHUuYlZVls7Ozz7P8E97fWsh3/rSON78zjckZcV32viLSu+zYsYMRI0Z4uowe0d6+GmPWWWuz2tu+I03ZGcA8Y8x+4M/AbGPMn07aJh9Ic39YABAN9Gj/x9TBcRjj9KOLiPRFZw10a+1PrLWp1toM4BbgI2vtydNTLwG+7n78Zfc2PXoufkxYEKMHRKsfXUT6rE53NhtjHjbGzHM/fRGIN8bkAv8G3N8VxZ2r6ZnxbDhYRk1Dkyc+XkR6SF+4dlNn9vGcAt1au/x4/7m19kFr7RL34zpr7U3W2iHW2inW2r3nXEkXmD4kgcZmS/b+Mk98vIj0gJCQEEpLS3061K21lJaWEhISck6v8/ozRVubnBFLoL9h9Z4SZg5L9HQ5ItINUlNTycvLo7i42NOldKuQkBBSU1PP6TU+FehhQQFMSIvV9dFFfFhgYCCDBg3ydBm9ks8N2J6WGc+W/Aoqaho9XYqISI/yuUCfMSQBa+GzfWqli0jf4n2BXnMU1j4PLle7q8enxRAa6M+nGo8uIn2M9wV67ofw3o8gd1m7q4MC/Jg8KE7j0UWkz/G+QB81HyIHwJrfn3aT6Znx5Byp5khlXQ8WJiLiWd4X6P6BcOG3Yd8KOLy53U1mZDoXj1+zV610Eek7vC/QASbdDkERp22ljxwQRVRIgK7rIiJ9incGemgMTPgX2PoWVOSfstrfzzAtM1796CLSp3hnoANM/Q5YF6xd1O7q6ZkJ5JXVcrC0+2bYFhHpTbw30GMzYMS1sO5lqK8+ZfWMIc60dJ/uUbeLiPQN3hvoANPuhroK2HDy5dkhMzGCpMhgVqvbRUT6CO8O9LTJkHYhfPY0uJrbrDLGMD0znjV7Snz6qmwiIsd5d6ADTLsLyg/AzndPWTU9M4GS6gZ2F53aJSMi4mu8P9AvuMbpT//01CGM09396Mu2F/ZwUSIiPc/7A93PH6Z+D/LWwqG1bValxoYxc1giL63ez7F6zWIkIr7N+wMdYPxXISQaPv3dKat+OGcoR4818OqaAx4oTESk5/hGoAdHQNY3nH70o/varJqYHsuXhiWyaMUeqtVKFxEf5huBDjBlIRg/+PzZU1b9cM5QymoaeXXN/p6vS0Skh/hOoEcNgNFfhvV/hNq2k0RPSI9l1vBEFq3Yq1a6iPgs3wl0gOnfh8ZjsO6VU1b9cM4wymsaeeXT/T1fl4hID/CtQO83BgZ9CT5/Dpoa2qwanxbDJcMTeX7lXqrqNN+oiPge3wp0gGnfh6oC2PZ/p6xSK11EfJnvBfqQOZAwHNb8Dk465X9cWgyzL0ji+ZX71EoXEZ/je4Hu5+dcDqBwC+xfecrqH84ZSkVtI39Yvb/naxMR6Ua+F+gAY2+GsIR2LwcwNjWGOSOSeGHVPirVShcRH+KbgR4YAlPuhJwPoHjXKavvuXSYWuki4nN8M9ABJn8LAkJgzf+csmpMajRzRiTzwsq9aqWLiM/w3UAPT4Bxt8CmP8OxU2ct+uGcoVTWNfHyqv09X5uISDfw3UAHmHoXNDfAil+dsmp0SjSXjUzmxVV7qahVK11EvJ9vB3riMKfr5fPn4ODnp6y+51J3K331vnZeLCLiXXw70AHm/ByiU2HJ96Gxrs2q0SnRXD4ymRdX7VMrXUS8nu8HenAkXPsklOyGFY+dsvqeOUOpqmvipVVqpYuId/P9QAcYcqkzCcaqJ+DwpjarRg2I5opRyby0ah8VNWqli4j36huBDnDFfzsjX/52FzS3De57Lh1GVX0TL6ovXUS82FkD3RgTYoxZa4zZZIzZZox5qJ1tbjfGFBtjNrpv3+qecs9DaCxc/RvnkgCrn2yzauSAKOaO6sfLaqWLiBfrSAu9HphtrR0HjAfmGmOmtrPdG9ba8e7bC11ZZJcZcS2MvB4+efSUM0jvmTOUqvomFq3c45naRETO01kD3Tqq3U8D3Td7hpf0blf9CoLC4W/fB1dzy+IR/aOYN24Az6/Yx+6iKg8WKCLSOR3qQzfG+BtjNgJHgGXW2lMHdcONxpjNxpjFxpi007zPQmNMtjEmu7i4uPNVn4+IJJj7KOSthbWL2qx68NqRRIQEcO+bm2hqdnmmPhGRTupQoFtrm62144FUYIoxZvRJm7wDZFhrxwLLgFPngHPeZ5G1Nstam5WYmHgeZZ+nsQtg6OXwz4fh6IkDoQkRwTw0bxSb8ip4QcMYRcTLnNMoF2ttOfAxMPek5aXW2nr30xeASV1SXXcxBq75LRh/eOcHbSbCuGZsf+aO6sfjy3aTe6T6DG8iItK7dGSUS6IxJsb9OBS4DNh50jb9Wz2dB+zowhq7R3QqXP4w7FsB60/8oDDG8P+uH01YkD/3Lt5Es8t7DxeISN/SkRZ6f+BjY8xm4AucPvR3jTEPG2Pmubf5gXtI4ybgB8Dt3VNuF5t4O2RcDEsfgIr8lsWJkU7Xy4aD5TqDVES8hrHWMy3QrKwsm52d7ZHPbuPoXnh6Ogz+Etz6Z6c7BrDWcuer61iZU8w/7rmYwYkRHi5URASMMeustVntres7Z4qeTtxgmP0z2P0+bFncstgYwy/mjyY4wI/7Fm9W14uI9HoKdICp34WULPjHfVB9YjhlUlQIP792FNkHynjl0/2eq09EpAMU6AB+/nDd76G+Cv76XWhqaFl1w8QULhmeyGMf7GR/yTEPFikicmYK9OOSRsBVj0HuMnjz9pZQN8bwyxvGEujvx31vbcalrhcR6aUU6K1lfQOu+jXs+jssvqMl1PtFh/DA1SNZu+8of/zsgIeLFBFpnwL9ZFPuhCt/BTvfbRPqN2WlMnNYIo++v5ODpTUeLlJE5FQK9PZcuLBtqDc3YozhkRvG4GcMP1bXi4j0Qgr007lwIVz5mBPqb94OzY0MiAnlP64ewZq9pby29qCnKxQRaUOBfiYXftu5MmOrlvotk9O4aEgCv3xvB3ll6noRkd5DgX42U7/jhPqOd2DxHRhXE7+8YQwAP35LJxyJSO+hQO+Iqd+BuY+4Q/0bpEUH8sA1I1mdW8ov3+v91yETkb4hwNMFeI2p33Uus/vBT+Ctb3LLjS+ys7CKF1btIyMhnNumDvR0hSLSxynQz8W07wEWPvgpAA/Mf4EDpcf4+ZJtpMeFMXOYByftEJE+T10u52raXXDFL2D73/B/+5v8bsEohiZFcNf/ridHc5GKiAcp0DvjeKjvWELEG1/m5ZszCQny544/fEFJdf3ZXy8i0g0U6J017S648UXIX0f/N6/l1esTKKmuZ+Gr2dQ1Nnu6OhHpgxTo52PMl+HrS6C2jBHvzufl2S7WHyzn3sWb8dTEISLSdynQz1f6VPjWhxAay7RVd7Bo4gHe2VTAbz/M8XRlItLHKNC7QnymE+opk7h8+094Jv1jnvrnbv5vQ56nKxORPkSB3lXC4uBrf4UxN3Hlked5Ke5V/mPxBr7Yf9TTlYlIH6FA70oBwXDD8zDzPmbXfMAfQx7j3175hAOlmulIRLqfAr2rGQOz/wOue5qJdjt/sD/j/pf+TkVNo6crExEfp0DvLhO+irntbQYGVvBU9Y947OXXaWhyeboqEfFhCvTuNPhLBCz8J2FhEfzsyL/zv8/9ggaNUReRbqJA726Jwwm/azkVcWO5o/hXbHjiRuqryzxdlYj4IAV6T4hIot/dS9kw9G4mVX9C5RNTadi/xtNViYiPUaD3FD9/Jnz1v1g27RVqG5rx/8NVNH38KLjUBSMiXUOB3sOunDuPzy7/K+80TyXgk1/g+sO1UJHv6bJExAco0D1gwUWjqb3mWf6t4TvUH1qPfWa6MxuSiMh5UKB7yK0XDuTC+XdxZd1/s685Cd64Dd75ITRo4mkR6RzNWORBN09Ox3A5c99O4PGEd7lm3ctwcI1zWd5+oz1dnoh4GQW6hy2YnIYxcPdbAWxJmcj9Nb/FPD8bvnSfc831wFBPlygiXkJdLr3ATVlp/PrL41iUn853Ip+iechl8NH/g99PgS2LncmpRUTOQoHeS9w4KZXf3DSOpQeaua3qbuq+8lcIjYa3vgkvXgaHvvB0iSLSyynQe5EbJqby+IJxfL6vlFuWBVF861K47n+g/CC8OAcWf9N5LCLSjrMGujEmxBiz1hizyRizzRjzUDvbBBtj3jDG5BpjPjfGZHRLtX3A/AmpPP3VSewsrGT+s5+Rm3Id3L0eZt4HO9+F30+Gfz4M9VWeLlVEepmOtNDrgdnW2nHAeGCuMWbqSdt8Eyiz1g4Bfgs82qVV9jFzR/fjjYXTqGt0Mf/pT/n0UJ1zSd6718GIebDyN/DURFj3is40FZEWZw1066h2Pw10304+Sncd8Ir78WLgUmOM6bIq+6BxaTH83/em0y8qhK+9tJa/ZB+C6FS48Xn41kcQNwje+QE8NxN2f6BgF5GO9aEbY/yNMRuBI8Aya+3nJ22SAhwCsNY2ARVAfBfW2SelxYWx+LvTmTo4nvsWb+bXH+zCWgupk+AbH8BNf4D6SnhtATw5DpY/qssIiPRhHQp0a22ztXY8kApMMcZ06qwXY8xCY0y2MSa7uLi4M2/R50SHBvLyHZO5OSuN33+cyz1/3khdY7MzM9Ko+fD9dU6wxw+B5b+AJ0bDazfDzvegucnT5YtIDzL2HMc4G2MeBGqstb9utewD4D+ttWuMMQFAIZBoz/DmWVlZNjs7u5Nl9z3WWp75ZA+Pvb+LrIGxLPpaFnHhQW03OroPNvwRNvwvVBdCZH8Y/1WY+C8Qm+GRukWkaxlj1llrs9pb15FRLonGmBj341DgMmDnSZstAb7ufvxl4KMzhbmcO2MM35s1hN9/ZQKb8yu44enV7C2ubrtR3CC49EH4121wy2vQbyysehyeHA9/nA/b/gpNDZ4oX0R6wFlb6MaYsTgHPP1x/gD8xVr7sDHmYSDbWrvEGBMC/BGYABwFbrHW7j3T+6qF3nnrDhzlzlfX4bKW526bxIWDz3C4oiIPNvwJ1v8RKvMgPBEmfh2y7nAOsoqIVzlTC/2cu1y6igL9/BwoPcYdf/iCQ0dreOSGsdw46Szh7GqGPR/BFy/C7vfB+MEFV8HkO2HQTKdPXkR6PQW6jyqvaeA7f1rHZ3uPctOkVB66bhRhQR243lrZAch+Cda/CrVHIWE4TLkTxt0CwZHdX7iIdJoC3Yc1Nbt44sMc/md5LoMTwvndrRMZOSCqYy9urINtb8PaRVCwAYIiYNytTrgnDu/ewkWkUxTofcCnuSXc88ZGKmobeeDqEdw2dSDndG5X3jon2Le9Dc0NTjfM5Dth6OUQGNJ9hYvIOVGg9xEl1fX86M1NLN9VzBWjknn0xrHEhAWd/YWtHSuB9a9A9stQcQgCQmDgDBhyKWTOhsQL1N8u4kEK9D7E5bK8uGofj76/k6TIYJ66dQJZGXHn/kbNTbB3OeQug9x/QmmOszwqBTIvgcxLYfAsCOvEe4tIpynQ+6BNh8q5+/UN5JfX8q9zhvLdWUPw9zuPlnX5QWeUzJ6PnKCvqwAMpEx0wj1zNqRmgX9gV+2CiLRDgd5HVdY18tO3t/Du5sNMz4zntzePJzmqC/rDm5ugYL0T7rn/hPxssC7noOrA6ZBxsdMH328M+Pmf/+eJSAsFeh9mreUv2Yf4+ZJthAUF8JubxnHJBUld+yG1ZbD3E9i3AvavhJLdzvKQGMi4yAn3QTPV/y7SBRToQk5RFXe/voGdhVXcOiWNn1w1gqiQbuoeqTzsBPu+Fc6t/ICzPDzxROt90EyIG6yAFzlHCnQBoK6xmceX7eaFlXtJjgrhlzeMYdbwLm6tt6fsQNuArzrsLI8c4LTgMy6CQRdD7CAFvMhZKNCljQ0Hy7h38WZyj1Tz5UmpPHD1SKLDeuhgprVQmuvunlnl3I4dcdZFpTgt+OMBHzNQAS9yEgW6nKKusZmn/pnDcyv2Eh8exC/mj2HOyOSeL8Rap8+9dcDXlDjrotOccB84A5JHOpcoCI7o+RpFehEFupzW5rxy7n1zM7uKqpg/IYWfXzvy3E9G6krWQvFO2LfS6abZv8q53sxx0WmQMMw5wJo43H0/DEJjPVezSA9SoMsZNTS5+P3HuTz9cS4xYUH81/WjmTu6n6fLcrhccHSPE/LFO6F4l3Mr2Q1NdSe2i0h2Aj5huBP4CUOcWZyiUsGvQxNziXgFBbp0yLaCCu59czPbD1dyzdj+PDRvFPERwZ4uq32uZudkp+JdUOIO+eOB39Bq4o+AUIjPdMI9fggkDIX4oc6y0BiPlS/SWQp06bDGZhfPLN/D7z7KISokkB9feQFfnpiK3/mcZdqTrIWqQufAa2kOlOSeeFx2AGzziW3DEyEuE2IHOlP0xWY4B2JjM5zp+9Syl15IgS7nbGdhJT95ewsbDpYzOiWKB68ZxZRBXn7dlqYGKNvvhHtpLpTkOM/L9kNlvnO263H+QRCTfiLgYzMgJs0ZahnZz7kF9NJfL+LTFOjSKS6XZcmmAh75x04KK+u4emx/7p97AWlxYZ4ures1NThXlyzb75wIVbbfadEff15bduprQuOclnxkP4jqf+JxpPtxfCaERPfwjoivU6DLealpaOK5T/by3Io9uCwsvHgw352VSXhwB2ZH8hW15c78rFWFzolRp9wfhuqitq18cII9YZj7gO2wE48jkjXGXjpFgS5doqC8lkff38nfNhaQHBXMfVdcwPwJKd7Tv97dXM1wrNgJ94p8ZyROyW73gdscaKg6sW1ItDvghzvDLiMHOAdpQ2NP3EKidXEzOYUCXbrUugNlPPzONjblVTAuNZoHrx3JpIFe3r/e3ayFyoKTQt59f/xM2fYER58a9KGxEBbf6nbS88Awtf59mAJdupzLZfnrxnwefX8nRZX1zBs3gPvmDic11gf717tbbbkzU1RtWdtbXfmpy2rLoOaou0//NP93A0Kc/v2weOePQXAkBIW7bxGtHh9/HnHicXi80x0UFN5z+y/nRIEu3eZYfRPPfrKHRSv2Yi18dWo6d10yhITeOn7dV7ianUlGakrbuR1130qds2wbapyx+Q3HnFvjsbO/f1CEM6wzIhki3PfhSRCR5F6W5PxSCI50bgEh+lXQQxTo0u3yy2t58sPdLF6XR2igP9+8aBDfmjm4+y7RK53nckFjjTvgWwV9fZVzHZ3qIqgudt8XOccFqovaH+lznF+A80cgOOpEyAdHnHgcFAmBoRAUBoHh7vsw55dAYGjbZYFhEBDkDB31D3aOI+iPRQsFuvSY3CPVPL5sF+9tKSQmLJDvzcrka9MyCAnUwT2v19RwItyrjzi/EOornT8EDdXOfcvNvby++sT6hmOctpvojIwT7gHBzhSH/kHu+2DncVDYGbqTwt1/ONyPQ6KciVeOH5cIivC6PxYKdOlxW/IqeOyDnazMKaFfVAg/uHQoN2WlEuivsy/7LGud6+801Di/EI7/Smisabusscb549HcAM2N0Fzf6nEDNNW3fdz6vdp0LdWcvSa/AGc0UWisO+hjnbAPiXF+OTTVQWOtc2uqc3+W+77186Z65w+DX4Dzi+L4vTn++Phy9/Nxt8KUOzv1z6hAF49Zs6eUxz7YyYaD5QxKCOdfLxvGNWP6a6ijdD9Xc6ugd4d9XaX7YHN5qwPPp3ncWOscGwgMdd/CTnoe6lwrKDDU+fVgLbianJttdj7f1dT23rofj7weJv5Lp3ZLgS4eZa3lwx1H+PUHu9hVVMXI/lH8++XDuGR4koJd5Bwp0KVXaHZZlmzK5/Fluzl0tJahSRHcOXMw140fQHCA+thFOkKBLr1KY7OLdzcX8Nwne9lZWEVSZDC3z8jgqxcOJDpUo2JEzkSBLr2StZaVOSU8v3IvK3NKCA/y5+bJ6XzjogydoCRyGgp06fW2FVTwwsp9vLOpAAtcPaY/C2cOZnSKrlYo0poCXbxGQXktL6/ex+trD1Fd38T0zHjunDmYLw1N1AFUERTo4oUq6xp5/fODvLx6P4WVdWQmhnP79AxumJjaty7bK3ISBbp4rYYmF3/fUsDLq/ezOa+CyJAAbs5K42vTMkiPVz+79D0KdPF61lrWHyzn5dX7+MfWQlzWMmdEMndMz2BaZjzGy07fFumsMwX6WX+7GmPSgFeBZJwLMSyy1j550jazgL8B+9yL3rbWPnweNYu0YYxh0sBYJg2M5XBFLX/67ACvfX6QZduLuKBfJLdPz+C68SmEBmk8u/RdZ22hG2P6A/2tteuNMZHAOuB6a+32VtvMAn5krb2mox+sFrqcr7rGZpZsLOCl1fvYWVhFTFggt05J5ytT0n1z3lMRzrOFbq09DBx2P64yxuwAUoDtZ3yhSDcLCfRnweQ0bspK5fN9R3l59T6e+2QPzyzfw4wh8SzISuOKUf10pUfpM86pD90YkwGsAEZbaytbLZ8FvAXkAQU4rfVt7bx+IbAQID09fdKBAwfOo3SRU+WX17I4O4831x0ir6yWqJAArp+QwoKsNI1pF5/QJQdFjTERwCfAf1tr3z5pXRTgstZWG2OuAp601g490/upy0W6k8tlWbO3lDe+OMT72wppaHIxakAUC7LSuH58CtFhusSAeKfzDnRjTCDwLvCBtfbxDmy/H8iy1pacbhsFuvSUippG/rYpnze+OMS2gkqCAvyYO6ofC7LSmJ4ZrxOWxKucV6AbZzzYK8BRa+0PT7NNP6DIWmuNMVOAxcBAe4Y3V6CLJ2zNr+DN7EP8dWMBFbWNpMSEMn9CCjdMTGFwYoSnyxM5q/MN9IuAlcAWwOVe/FMgHcBa+6wx5vvAd4EmoBb4N2vtp2d6XwW6eFJdYzMfbCvk7fX5rMwpxmVhQnoMN0xM5dqx/YkJC/J0iSLt0olFImdQVFnH3zbm89a6fHYVVRHk78fsC5K4YWIKs4YnERSgafOk91Cgi3SAtZbthyt5a10+SzblU1LdQFx4EPPGDeCGiSmMSYnWGanicQp0kXPU2OxiZU4xb63PZ9n2IhqaXGQmhnP12AFcPaY/w5IjFO7iEQp0kfNQUdvI3zcfZsmmfD7fdxRrccJ9TH+uGtuf4cmRCnfpMQp0kS5ypKqOD7YW8vcth1m77yguC4Pd4X61wl16gAJdpBsUV9Xz/rZC3tt8mM/3lbYJ96vG9OeCfgp36XoKdJFuVlJdz/tbC3lvy2E+2+uEe3pcGJeNTOaykclkDYwlwF+jZeT8KdBFelBJdT1LtxWxbHshq/eU0tDkIjYskNkXJHP5qGQuHppAWJBmXZLOUaCLeEh1fRMrdhezbHsRH+08QkVtI8EBflw8NIHLR/Zj9ogkEiKCPV2meJHzunyuiHReRHAAV7n71BubXXyx7yhLtxexbHsRH+44gjEwKT22pWtGlx+Q86EWuogHHD+Jaem2IpZuL2LHYedq1JmJ4Vw2sh+XjUxmQlqMLhwmp1CXi0gvl1dWw4fbi1i2o4jP9x6lyWVJiAhmzogkLhuZzIwhCZqoQwAFuohXqahpZPnuIyzdXsQnu4qprm8iNNCfi4cmcNnIZGZfkES8+t37LAW6iJeqb2rms71HWba9kA+3H6Gwsg6AEf2juGhIPDOGJDBlUJxGzfQhCnQRH2CtZUt+BSt2F7Mqt4T1B8ppaHYR6G+YmB7LjCEJzBiSwLjUaI1592EKdBEfVNvQzBf7j7I6t4TVe0rYVlCJtRAZHMCFg+OZ4W7BD0mM0MFVH6JhiyI+KDTIn5nDEpk5LBGAo8caWLOnlFW5JXy6p4QPdxQBEBUSwPj0WCamxzAxPZbx6TFEhWhOVV+kFrqIjzp0tIbP9pay/mA5Gw6WsauoCmvBGBiWFMnEgTFMSI9lYnosgxPC1Yr3EupyERGq6hrZdKiC9QfLWH+wjA0Hy6mobQQgOjSQCekxTEqPZeLAWMalxRARrB/wvZG6XESEyJBALhqawEVDEwBwuSx7S6pZf6C8JeQ/2V2MteBnYFhyJJMGOi34iQNjyYgP09Ujezm10EWkRWVdIxsPlrPugBPwGw+WU1XfBEBceBAT009004xPiyE0SCc79TS10EWkQ6JCAtscaG12WXKPVLP+YFlLyH+44wgAAX6GkQOimDQwlkkDY8kaGEe/6BBPlt/nqYUuIuek7FgDGw45AZ+9v4xNeeXUNboASIkJdcI9wwn5C/pF4a+DrV1KLXQR6TKx4UHMviCZ2RckA86E2tsLKsk+UMb6A2V8vq+UJZsKAAgP8nd30cQwOiWaManR9IsKUV98N1ELXUS6lLWWvLJa1h90WvDZB8rYVViJyx018eFBjE6JZnRKFGNSohmdEk1KTKhCvoPUQheRHmOMIS0ujLS4MK4bnwI4Z7XuKKxka34FW/Iq2FpQyXOf7KXJnfKxYYGMTolm1IBoxqREMzY1mtRYhfy5UqCLSLcLDfJ3hj+mx7Ysq2tsZmdhFVvzK5xbQQUvrtpLY7MT8jFhgS3hPiYlhrGp0fSPVnfNmSjQRcQjQgL9GZ8Ww/i0mJZl9U3N7C6sZnN+OVvyKticV9GmJZ8QEcSYlGjGpMYw1h32SVEaWXOcAl1Eeo3gAH/GpDoHT7nQWVbX2MyOw5VscXfXbMmv4JPdOS198kmRwYxJiWZUitNdMyYlmuSo4D7Zklegi0ivFhLojJSZ0Kq7pqahiR2HK9l0yOmu2ZJfwce7jrSEfEJEMGNaHXTtK6NrFOgi4nXCggKYNDCOSQPjWpYdD3mnFe8cgP1kd3GrkA9iRP8ohidHMqxfJMOTIxmaHOFTk4P4zp6ISJ/WXsjXNjSz/XAl2wqc7pqdhVX88bMD1Dc5J0IZA+lxYQxLjmwT9IMSwgkK8L5JQhToIuKzQoP8Wy5NcFyzy3LwaA27CqvYXVTFrqIqdhdW8dHOIzS7m/MBfobMxAhGDYhiVEo0owZEMXJAVK+/jrwCXUT6FH8/w6CEcAYlhDN3dL+W5fVNzewtPuaEfGEVOw5Xsiq3hLc35LdsMzA+zAn5AdEt94mRvWfCbgW6iAjOCJsR/aMY0T+qzfIjVXVsK6hke0Gle8x8Je9tKWxZnxwVzKgB0QxLjmRoUgRDkyPITIwg3APXk1egi4icQVJkCEnDQ7hkeFLLsoraRrYXOH3zzn0lK3OKW06KAudCZUOTI5yQT4pkSHIEQ5IiurXbRoEuInKOokMDmZYZz7TM+JZlTc0uDhytIaeomtwjVeQcqSanqJo1e0pbDsKC06L/1kWDuXPm4C6v66yBboxJA14FkgELLLLWPnnSNgZ4ErgKqAFut9au7/JqRUR6qQB/PzITne4WONE33+yy5JU5QZ9zpJqcI1UkRXVPv3tHWuhNwL9ba9cbYyKBdcaYZdba7a22uRIY6r5dCDxDy3leIiJ9l7+fYWB8OAPjw5kzMrlbP+usAy2ttYePt7attVXADiDlpM2uA161js+AGGNM/y6vVkRETuucRs4bYzKACcDnJ61KAQ61ep7HqaGPMWahMSbbGJNdXFx8jqWKiMiZdDjQjTERwFvAD621lZ35MGvtImttlrU2KzExsTNvISIip9GhQDfGBOKE+f9aa99uZ5N8IK3V81T3MhER6SFnDXT3CJYXgR3W2sdPs9kS4GvGMRWosNYe7sI6RUTkLDoyymUG8C/AFmPMRveynwLpANbaZ4H3cIYs5uIMW7yjyysVEZEzOmugW2tXAWe8iLB1Zpq+q6uKEhGRc+d914cUEZF2Gadx7YEPNqYYONDJlycAJV1YTm/k6/vo6/sHvr+P2j/PGGitbXeYoMcC/XwYY7KttVmerqM7+fo++vr+ge/vo/av91GXi4iIj1Cgi4j4CG8N9EWeLqAH+Po++vr+ge/vo/avl/HKPnQRETmVt7bQRUTkJAp0EREf4XWBboyZa4zZZYzJNcbc7+l6upoxZr8xZosxZqMxJtvT9XQFY8xLxpgjxpitrZbFGWOWGWNy3PexnqzxfJxm//7TGJPv/h43GmOu8mSN58MYk2aM+dgYs90Ys80Yc497uS99h6fbR6/6Hr2qD90Y4w/sBi7Dueb6F8CtJ82e5NWMMfuBLGttbzyhoVOMMTOBapxJUEa7lz0GHLXWPuL+wxxrrf2xJ+vsrNPs338C1dbaX3uytq7gnqymf+tZy4Drgdvxne/wdPu4AC/6Hr2thT4FyLXW7rXWNgB/xpktSXoxa+0K4OhJi68DXnE/fgXnP49XOs3++YwzzFrmS99hR2Zm6/W8LdA7NDOSl7PAUmPMOmPMQk8X042SW11iuRBnEnJf831jzGZ3l4zXdke0dtKsZT75HbYzM5vXfI/eFuh9wUXW2ok4E2/f5f4579PcV+v0nr6/jnkGyATGA4eB33i0mi5wplnLfOU7bGcfvep79LZA9/mZkay1+e77I8D/4XQz+aKi4xOJu++PeLieLmWtLbLWNltrXcDzePn3eJpZy3zqO2xvH73te/S2QP8CGGqMGWSMCQJuwZktyScYY8LdB2QwxoQDlwNbz/wqr7UE+Lr78deBv3mwli53POjc5uPF3+MZZi3zme/wdPvobd+jV41yAXAPG3oC8Adestb+t2cr6jrGmME4rXJwJh95zRf2zxjzOjAL53KkRcDPgb8Cf8GZ+eoAsMBa65UHFk+zf7NwfqZbYD/wbW+dltEYcxGwEtgCuNyLf4rTx+wr3+Hp9vFWvOh79LpAFxGR9nlbl4uIiJyGAl1ExEco0EVEfIQCXUTERyjQRUR8hAJdRMRHKNBFRHzE/wc0cEgKXOOarAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "moderate-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "nearby-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "focal-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cathedral-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-player",
   "metadata": {},
   "source": [
    "### Step 4. 실제 결과와 요약문 비교\n",
    "#### Model test ( attractive summary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "coated-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "elementary-franklin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<원문> : losing smartphone could almost terrorist attack uk based study asked rank life events order stress revealed study also found younger people worried losing smartphones researchers believe result living modern life adding stress \n",
      "[실제 요약] : losing smartphone is as as terror attack study \n",
      "[예측 요약] :  study claims of how can kill humans\n",
      "\n",
      "\n",
      "<원문> : among list indian startup shutdowns chennai based homestay startup stayzilla announced shutdown february gurugram based food technology startup shut september failing raise capital delhi based logistics supply chain delivery bengaluru based fintech startup also shut shop due lack funding \n",
      "[실제 요약] : which indian startups faced shutdown in \n",
      "[예측 요약] :  indian startup launches its services services\n",
      "\n",
      "\n",
      "<원문> : rashtriya janata dal president lalu prasad yadav said lead party prison like previous occasions nda government puts jail yadav elected national president rjd tenth consecutive time tuesday reportedly spent days jail \n",
      "[실제 요약] : will lead rjd from jail if put behind bars lalu prasad \n",
      "[예측 요약] :  lalu yadav is the first time to be into bihar\n",
      "\n",
      "\n",
      "<원문> : maharashtra cm devendra fadnavis visited one virgin hyperloop one test sites us earlier week visit follows mou signed state government virgin group build mumbai pune hyperloop estimated cost crore hyperloop expected reduce travel time two cities minutes \n",
      "[실제 요약] : maharashtra cm visits virgin hyperloop one test site in us \n",
      "[예측 요약] :  maha cm to be in space for first time in yrs\n",
      "\n",
      "\n",
      "<원문> : actors deepika padukone irrfan khan feature together filmmaker vishal bhardwaj upcoming film film reportedly gangster drama produced vishal directed debutant honey deepika playing role mafia queen khan irrfan play local gangster reports added \n",
      "[실제 요약] : deepika irrfan to feature in vishal bhardwaj film \n",
      "[예측 요약] :  deepika to feature in film on irrfan khan film reports\n",
      "\n",
      "\n",
      "<원문> : nineteen time grand slam champion roger federer took twitter congratulate hometown club fc victory champions league manchester united words cannot possibly describe incredible moment club wow congrats team federer wrote scored th minute hand united first loss champions league season \n",
      "[실제 요약] : federer congratulates hometown team for beating man utd \n",
      "[예측 요약] :  federer shares pic with his man utd with his win\n",
      "\n",
      "\n",
      "<원문> : us president donald trump got confused group handshake aimed showing unity asean summit philippines capital manila trump failed whose hands supposed holding broke chain us president used hands fingers vietnamese prime minister nguyen \n",
      "[실제 요약] : trump gets confused while doing the asean group handshake \n",
      "[예측 요약] :  trump cancels his portrait of his own official\n",
      "\n",
      "\n",
      "<원문> : isro reportedly planning set satellite ground control station north pole orbit coverage efficiently download data india earth observing satellites isro already two ground stations telangana built antarctica space agency would also install second antenna aid project \n",
      "[실제 요약] : isro planning its st satellite control base at north pole \n",
      "[예측 요약] :  isro to launch satellite on satellite\n",
      "\n",
      "\n",
      "<원문> : captain harry kane scored twice including injury time goal help england win fifa world cup opener tunisia monday year old became first english footballer score two goals world cup match since gary tunisia goal first african nation year world cup \n",
      "[실제 요약] : scores in injury time to help england start wc with win \n",
      "[예측 요약] :  nba player scores goals in minutes after wc win\n",
      "\n",
      "\n",
      "<원문> : recently concluded four match test series india australia drew record viewership crore gross impressions broadcaster star sports claims third test two sides recorded viewership crore earlier year odi series india england became highest rated bilateral odi series last five years \n",
      "[실제 요약] : india australia test series drew record \n",
      "[예측 요약] :  australia to get crore in ipl highest ever\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"<원문> :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"[실제 요약] :\", seq2headlines(decoder_input_test[i]))\n",
    "    print(\"[예측 요약] :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-entertainment",
   "metadata": {},
   "source": [
    "#### Model 재설정 -1 : optimizer 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "turkish-doctor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "308/308 [==============================] - 332s 1s/step - loss: 1.9858 - val_loss: 2.6231\n",
      "Epoch 2/10\n",
      "308/308 [==============================] - 317s 1s/step - loss: 1.8685 - val_loss: 2.6149\n",
      "Epoch 3/10\n",
      "308/308 [==============================] - 316s 1s/step - loss: 1.7919 - val_loss: 2.6168\n",
      "Epoch 4/10\n",
      "308/308 [==============================] - 316s 1s/step - loss: 1.7288 - val_loss: 2.6262\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy') # optimizer -> adam 으로 변경\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) # 조기 종료 조건 설정\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "developmental-fraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-butter",
   "metadata": {},
   "source": [
    "#### Model 재설정 -2\n",
    "- 지금 가지고 있는 데이터는 하나하나의 원문의 길이가 그렇게 길지 않다. 하지만 그에 반해 비교하는 단어의 수는 몇 만개가 되기 때문에 상대적으로 accuracy가 낮아질 수 밖에 없는 구조라고 생각된다. 따라서 vocabulary(단어사전) 사이즈를 최대한 줄여서 재실험 해보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "subject-library",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69534\n",
      "등장 빈도가 24번 이하인 희귀 단어의 수: 58531\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11003\n",
      "단어 집합에서 희귀 단어의 비율: 84.17608651882531\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 8.691421627450618\n"
     ]
    }
   ],
   "source": [
    "threshold = 25 # 빈도수 제한 : 7 미만 -> 25 로 설정한다\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "patent-bruce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a017475039c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrc_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;31m# 단어 집합크기 제한\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msrc_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 단어 집합 재생성.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "src_vocab = 10000 # 단어 집합크기 제한\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab)\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "contemporary-marathon",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-104b63d1af8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 텍스트 시퀀스를 정수 시퀀스로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_input_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoder_input_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Headlines' 에 대해 동일하게 처리\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 13 # 기존의 7 -> 13 로 설정한다\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 6000 # 위의 결과에 따라 설정\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경 된 vocabulary를 이용한 모델 재 훈련\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy') # optimizer = adam\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) # 조기 종료 조건 설정\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=10) # epochs 10으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경 된 vocabulary를 이용한 모델 재 훈련\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy') # optimizer = adam\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) # 조기 종료 조건 설정\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50) # epochs 10으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-calculator",
   "metadata": {},
   "source": [
    "### Step 5. Summa 사용\n",
    "#### Extractive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize # Extractive summary를 위한 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, text in enumerate(data2['text'][:10]):\n",
    "    print(f'<Original_{idx+1}:> \\n{text}')\n",
    "    print(f'[Summary:] \\n{summarize(text, words=20)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-train",
   "metadata": {},
   "source": [
    "평가문항|상세기준\n",
    "---|---\n",
    "1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.|분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.|모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.\n",
    "3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.|두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
