{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "democratic-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-lobby",
   "metadata": {},
   "source": [
    "인공지능 모델의 입력이 될 수 있는 것은 0과 1의 비트로 표현 가능한 숫자만으로 이루어진 매트릭스일뿐입니다.\n",
    "\n",
    "\n",
    "우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 벡터를 짝지어 보려고 하는 것입니다. 그런데 그 벡터는 어디서 가져올까요? 그렇습니다. 우리는 딥러닝을 통해 그 벡터를 만들어 낼 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "단 3개의 짧은 문장으로 이루어진 텍스트 데이터를 처리하는 간단한 예제를 생각해 보겠습니다.\n",
    "\n",
    "\n",
    "\n",
    "- i feel hungry\n",
    "- i eat lunch\n",
    "- now i feel happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlimited-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-honolulu",
   "metadata": {},
   "source": [
    "- 텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리(dict) 자료구조로 표현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "responsible-sending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "happy-titanium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-building",
   "metadata": {},
   "source": [
    "- 이 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "devoted-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-trust",
   "metadata": {},
   "source": [
    "- 우리가 가진 텍스트 데이터를 숫자로 바꿔 표현해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "entitled-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-glucose",
   "metadata": {},
   "source": [
    "- get_encoded_sentence 함수를 통해 아래와 같이 맵핑된 것이 확인되시나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "complicated-logging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-poverty",
   "metadata": {},
   "source": [
    "- encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "genetic-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "suspended-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-afghanistan",
   "metadata": {},
   "source": [
    " 'i feel hungry'가 1, 3, 4, 5 로 변환되었지만 이 벡터는 텍스트에 담긴 언어의 의미와 대응되는 벡터가 아니라 임의로 부여된 단어의 순서에 불과합니다. 우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 벡터를 짝짓는 것이었습니다. 그래서 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 됩니다. Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미벡터 파라미터를 구현한 Embedding 레이어를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-translation",
   "metadata": {},
   "source": [
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-9-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-techno",
   "metadata": {},
   "source": [
    "아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "framed-imagination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow import keras\\n\\nvocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\\nword_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \\n\\nembedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\\n\\n# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \\nraw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\\noutput = embedding(raw_inputs)\\nprint(output)\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "macro-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "verified-lindsay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.04984901  0.01645     0.02844573  0.0103211 ]\n",
      "  [ 0.01833221  0.02182427  0.02183843  0.02935094]\n",
      "  [ 0.00036407 -0.00935979 -0.03087335  0.04780081]\n",
      "  [-0.03028523  0.01516971  0.03639379 -0.01649436]\n",
      "  [ 0.0409963  -0.01570584 -0.02081732  0.03285512]]\n",
      "\n",
      " [[-0.04984901  0.01645     0.02844573  0.0103211 ]\n",
      "  [ 0.01833221  0.02182427  0.02183843  0.02935094]\n",
      "  [ 0.01231734 -0.02211572  0.03300575 -0.046796  ]\n",
      "  [ 0.02767427 -0.04409636 -0.04468126  0.04261169]\n",
      "  [ 0.0409963  -0.01570584 -0.02081732  0.03285512]]\n",
      "\n",
      " [[-0.04984901  0.01645     0.02844573  0.0103211 ]\n",
      "  [-0.00598462 -0.04913318 -0.02812618 -0.03283997]\n",
      "  [ 0.01833221  0.02182427  0.02183843  0.02935094]\n",
      "  [ 0.00036407 -0.00935979 -0.03087335  0.04780081]\n",
      "  [ 0.01366893 -0.00043305  0.03459518 -0.03009672]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-scenario",
   "metadata": {},
   "source": [
    "Q) output의 shape=(3, 5, 4)에서 3, 5, 4의 의미는 각각 무엇일까요?\n",
    "\n",
    "A)3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-kuwait",
   "metadata": {},
   "source": [
    "텍스트 데이터를 다루는 데 주로 사용되는 딥러닝 모델은 바로 Recurrent Neural Network(RNN)입니다. RNN은 시퀀스(Sequence) 형태의 데이터를 처리하기에 최적인 모델로 알려져 있습니다.\n",
    "\n",
    "\n",
    "- at time=0s : 듣는이의 귀에 들어온 input='i'\n",
    "- at time=1s : 듣는이의 귀에 들어온 input='feel'\n",
    "- at time=2s : 듣는이의 귀에 들어온 input='hungry'\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/E-9-3.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-tennis",
   "metadata": {},
   "source": [
    "Q) 위 그림에서 대화가 stateful한지 stateless한지 결정하는 것은 직원인가요, 아니면 손님인가요? 그렇게 생각하는 이유는 무엇인가요?\n",
    "\n",
    "\n",
    "A)Stateful한 대화에서는 손님이 이전 시점에 어떤 선택을 했는지 직원이 기억을 하지만, Stateless한 대화에서는 직원이 기억하지 못한다. 그래서 손님 스스로 본인이 이전 시점에 했던 선택을 모두 기억하고 있다가 직원에게 매번 새롭게 전달해야 한다. 손님의 이전 주문내역을 기억하는 직원은 stateful하고, 그렇지 못한 직원은 stateless하다.\n",
    "\n",
    "[참고영상](https://youtu.be/-SHPG_KMUkQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aggressive-contractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-browse",
   "metadata": {},
   "source": [
    "텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)를 사용할 수도 있습니다.\n",
    "\n",
    "우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다. 이미지는 시퀀스 데이터가 아닙니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다.\n",
    "\n",
    "그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용됩니다. 이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율을 보여줍니다.\n",
    "\n",
    "그리고 CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습 속도도 훨씬 빠르게 진행된다는 장점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "extraordinary-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "recent-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-journalist",
   "metadata": {},
   "source": [
    "- 이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "neural-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rolled-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-distinction",
   "metadata": {},
   "source": [
    "- 텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "- 이미 텍스트가 encode되었으므로 IMDb 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accessible-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-leonard",
   "metadata": {},
   "source": [
    "IMDb 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 합니다. 아래 내용은 Tensorflow 튜토리얼의 가이드를 반영하여 작성하였습니다.\n",
    "word_to_index는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "quiet-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-perfume",
   "metadata": {},
   "source": [
    "다운받은 데이터셋이 확인되었습니다. 마지막으로, encode된 텍스트가 정상적으로 decode되는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "thrown-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-empty",
   "metadata": {},
   "source": [
    "decode한 문장과 라벨을 비교하여 일치하는지 확인해 볼까요?\n",
    "\n",
    "\n",
    "pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "applicable-governor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "capital-louisville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n",
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "looking-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 162,689\n",
      "Trainable params: 162,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation=\"relu\"))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "recent-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sporting-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 9s 167ms/step - loss: 0.6933 - accuracy: 0.5025 - val_loss: 0.6930 - val_accuracy: 0.5013\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6925 - accuracy: 0.5064 - val_loss: 0.6924 - val_accuracy: 0.5014\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6903 - accuracy: 0.5132 - val_loss: 0.6913 - val_accuracy: 0.5029\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6821 - accuracy: 0.5200 - val_loss: 0.6959 - val_accuracy: 0.5066\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6746 - accuracy: 0.5337 - val_loss: 0.7000 - val_accuracy: 0.5077\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6689 - accuracy: 0.5400 - val_loss: 0.7034 - val_accuracy: 0.5074\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6684 - accuracy: 0.5346 - val_loss: 0.7075 - val_accuracy: 0.5078\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6650 - accuracy: 0.5403 - val_loss: 0.7008 - val_accuracy: 0.5062\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6631 - accuracy: 0.5358 - val_loss: 0.7177 - val_accuracy: 0.5082\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6590 - accuracy: 0.5409 - val_loss: 0.7165 - val_accuracy: 0.5078\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6555 - accuracy: 0.5403 - val_loss: 0.7144 - val_accuracy: 0.5070\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6518 - accuracy: 0.5427 - val_loss: 0.7248 - val_accuracy: 0.5072\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6521 - accuracy: 0.5395 - val_loss: 0.7261 - val_accuracy: 0.5076\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6518 - accuracy: 0.5416 - val_loss: 0.7358 - val_accuracy: 0.5072\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6508 - accuracy: 0.5449 - val_loss: 0.7376 - val_accuracy: 0.5062\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6514 - accuracy: 0.5348 - val_loss: 0.7462 - val_accuracy: 0.5066\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6513 - accuracy: 0.5383 - val_loss: 0.7497 - val_accuracy: 0.5075\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.6497 - accuracy: 0.5394 - val_loss: 0.7538 - val_accuracy: 0.5069\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6472 - accuracy: 0.5394 - val_loss: 0.7538 - val_accuracy: 0.5047\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.6514 - accuracy: 0.5388 - val_loss: 0.7696 - val_accuracy: 0.5066\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "incorrect-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 17s - loss: 0.7479 - accuracy: 0.5114\n",
      "[0.7479433417320251, 0.5113999843597412]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "separated-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "graduate-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "social-message",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "starting-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "protecting-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "stone-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02853709,  0.00612236, -0.05136837, -0.0208081 , -0.04423995,\n",
       "       -0.01346434,  0.05463878,  0.0242752 ,  0.04319183,  0.06976275,\n",
       "        0.05517597, -0.06415652, -0.00303474, -0.01583116,  0.03202609,\n",
       "        0.04221706], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "increasing-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solid', 0.9556260704994202),\n",
       " ('representing', 0.940754771232605),\n",
       " ('sugar', 0.934616208076477),\n",
       " ('cheerful', 0.9339861869812012),\n",
       " ('says', 0.9337359666824341),\n",
       " ('wet', 0.9304290413856506),\n",
       " ('accompanied', 0.9289153814315796),\n",
       " ('moore', 0.9283976554870605),\n",
       " ('darth', 0.9234687089920044),\n",
       " ('twisted', 0.9233026504516602)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "valued-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02853709,  0.00612236, -0.05136837, -0.0208081 , -0.04423995,\n",
       "       -0.01346434,  0.05463878,  0.0242752 ,  0.04319183,  0.06976275,\n",
       "        0.05517597, -0.06415652, -0.00303474, -0.01583116,  0.03202609,\n",
       "        0.04221706], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "affiliated-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solid', 0.9556260704994202),\n",
       " ('representing', 0.940754771232605),\n",
       " ('sugar', 0.934616208076477),\n",
       " ('cheerful', 0.9339861869812012),\n",
       " ('says', 0.9337359666824341),\n",
       " ('wet', 0.9304290413856506),\n",
       " ('accompanied', 0.9289153814315796),\n",
       " ('moore', 0.9283976554870605),\n",
       " ('darth', 0.9234687089920044),\n",
       " ('twisted', 0.9233026504516602)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "modified-submission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "false-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "transsexual-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "lesser-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 20s 503ms/step - loss: 0.6935 - accuracy: 0.5022 - val_loss: 0.6914 - val_accuracy: 0.5130\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.6857 - accuracy: 0.5512 - val_loss: 0.6772 - val_accuracy: 0.5781\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.6512 - accuracy: 0.6278 - val_loss: 0.5859 - val_accuracy: 0.7206\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.5078 - accuracy: 0.7955 - val_loss: 0.3847 - val_accuracy: 0.8414\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 10s 319ms/step - loss: 0.3228 - accuracy: 0.8749 - val_loss: 0.3391 - val_accuracy: 0.8538\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 9s 319ms/step - loss: 0.2379 - accuracy: 0.9084 - val_loss: 0.3055 - val_accuracy: 0.8717\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.1768 - accuracy: 0.9363 - val_loss: 0.2962 - val_accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.1276 - accuracy: 0.9633 - val_loss: 0.3038 - val_accuracy: 0.8770\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 9s 319ms/step - loss: 0.1009 - accuracy: 0.9744 - val_loss: 0.3128 - val_accuracy: 0.8791\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 10s 319ms/step - loss: 0.0727 - accuracy: 0.9844 - val_loss: 0.3245 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0515 - accuracy: 0.9931 - val_loss: 0.3423 - val_accuracy: 0.8770\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 10s 344ms/step - loss: 0.0356 - accuracy: 0.9968 - val_loss: 0.3683 - val_accuracy: 0.8727\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0259 - accuracy: 0.9980 - val_loss: 0.3836 - val_accuracy: 0.8729\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0169 - accuracy: 0.9992 - val_loss: 0.4125 - val_accuracy: 0.8717\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 0.4203 - val_accuracy: 0.8760\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0091 - accuracy: 0.9996 - val_loss: 0.4369 - val_accuracy: 0.8753\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 10s 322ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 0.4568 - val_accuracy: 0.8729\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 11s 359ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 0.4648 - val_accuracy: 0.8731\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 10s 319ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.4776 - val_accuracy: 0.8741\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8753\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "special-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.5347 - accuracy: 0.8600\n",
      "[0.5346617698669434, 0.860040009021759]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "technological-going",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/sentiment_classification/data/ratings_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-474f69424950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 데이터를 읽어봅시다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/sentiment_classification/data/ratings_train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/sentiment_classification/data/ratings_test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m             )\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/sentiment_classification/data/ratings_train.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "[13]:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-sterling",
   "metadata": {},
   "source": [
    "# 노드제출란"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "occupied-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "french-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "talented-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "matched-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.\n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 4 이 출력됩니다.\n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "worldwide-directory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다.\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "unlimited-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "excellent-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               1083392   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,243,905\n",
      "Trainable params: 1,243,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "HIDDEN_SIZE = 512\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim))\n",
    "model.add(keras.layers.LSTM(HIDDEN_SIZE))\n",
    "model.add(keras.layers.Dense(1, 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "neutral-association",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n",
      "(10000, 580)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "communist-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6802 - val_accuracy: 0.5599\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.6744 - accuracy: 0.5766 - val_loss: 0.6704 - val_accuracy: 0.6254\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.6601 - accuracy: 0.6919 - val_loss: 0.6392 - val_accuracy: 0.6545\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.6173 - accuracy: 0.6999 - val_loss: 0.6201 - val_accuracy: 0.6549\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.5412 - accuracy: 0.7564 - val_loss: 0.3736 - val_accuracy: 0.8349\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.3036 - accuracy: 0.8715 - val_loss: 0.3281 - val_accuracy: 0.8600\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.2978 - accuracy: 0.8786 - val_loss: 0.3648 - val_accuracy: 0.8362\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.4688 - accuracy: 0.7898 - val_loss: 0.5235 - val_accuracy: 0.7386\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.6406 - accuracy: 0.7806 - val_loss: 0.4010 - val_accuracy: 0.8199\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.2683 - accuracy: 0.9012 - val_loss: 0.3437 - val_accuracy: 0.8626\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 51s 2s/step - loss: 0.1922 - accuracy: 0.9275 - val_loss: 0.4060 - val_accuracy: 0.8425\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.1760 - accuracy: 0.9339 - val_loss: 0.3390 - val_accuracy: 0.8620\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.1392 - accuracy: 0.9519 - val_loss: 0.3630 - val_accuracy: 0.8657\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.1110 - accuracy: 0.9644 - val_loss: 0.3633 - val_accuracy: 0.8579\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.0959 - accuracy: 0.9696 - val_loss: 0.4063 - val_accuracy: 0.8623\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.0868 - accuracy: 0.9747 - val_loss: 0.4161 - val_accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.0677 - accuracy: 0.9826 - val_loss: 0.4132 - val_accuracy: 0.8470\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.1049 - accuracy: 0.9637 - val_loss: 0.4917 - val_accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.1647 - accuracy: 0.9402 - val_loss: 0.4583 - val_accuracy: 0.8425\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.0697 - accuracy: 0.9792 - val_loss: 0.4724 - val_accuracy: 0.8499\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-universal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
